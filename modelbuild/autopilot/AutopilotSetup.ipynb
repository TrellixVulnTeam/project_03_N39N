{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Autopilot\n",
    "\n",
    "This notebook sets up auto pilot job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"sagemaker/DEMO-automl-parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use [PyArrow](https://arrow.apache.org/docs/python/) library to store the Abalone dataset in the Parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "# Download the dataset and load into a pandas dataframe\n",
    "FILE_NAME = \"abalone.csv\"\n",
    "s3.download_file(\"sagemaker-sample-files\", f\"datasets/tabular/uci_abalone/abalone.csv\", FILE_NAME)\n",
    "\n",
    "feature_names = [\n",
    "    \"Sex\",\n",
    "    \"Length\",\n",
    "    \"Diameter\",\n",
    "    \"Height\",\n",
    "    \"Whole weight\",\n",
    "    \"Shucked weight\",\n",
    "    \"Viscera weight\",\n",
    "    \"Shell weight\",\n",
    "    \"Rings\",\n",
    "]\n",
    "data = pd.read_csv(FILE_NAME, header=None, names=feature_names)\n",
    "\n",
    "data.to_parquet(\"abalone.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sagemaker.Session().upload_data(\"abalone.parquet\", bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the parameters, we kick off training, and poll for status until training is completed, which in this example, takes under 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "job_name = \"autopilot-parquet-\" + strftime(\"%m-%d-%H-%M\", gmtime())\n",
    "print(\"AutoML job:\", job_name)\n",
    "\n",
    "create_auto_ml_job_params = {\n",
    "    \"AutoMLJobConfig\": {\n",
    "        \"CompletionCriteria\": {\n",
    "            \"MaxCandidates\": 5,\n",
    "        }\n",
    "    },\n",
    "    \"AutoMLJobName\": job_name,\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ContentType\": \"x-application/vnd.amazon+parquet\",\n",
    "            \"CompressionType\": \"None\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": f\"s3://{bucket}/{prefix}/abalone.parquet\",\n",
    "                }\n",
    "            },\n",
    "            \"TargetAttributeName\": \"Rings\",\n",
    "        }\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": f\"s3://{bucket}/{prefix}/output\"},\n",
    "    \"RoleArn\": role,\n",
    "}\n",
    "\n",
    "client = boto3.client(\"sagemaker\", region_name=region)\n",
    "client.create_auto_ml_job(**create_auto_ml_job_params)\n",
    "\n",
    "response = client.describe_auto_ml_job(AutoMLJobName=job_name)\n",
    "status = response[\"AutoMLJobStatus\"]\n",
    "secondary_status = response[\"AutoMLJobSecondaryStatus\"]\n",
    "print(f\"{status} - {secondary_status}\")\n",
    "\n",
    "while status != \"Completed\" and secondary_status != \"Failed\":\n",
    "    time.sleep(60)\n",
    "    response = client.describe_auto_ml_job(AutoMLJobName=job_name)\n",
    "    status = response[\"AutoMLJobStatus\"]\n",
    "    secondary_status = response[\"AutoMLJobSecondaryStatus\"]\n",
    "    print(f\"{status} - {secondary_status}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}